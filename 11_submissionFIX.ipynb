{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2894bf7e-912c-4bc2-97cd-3c89a6af3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, copy, cv2, sys, random, logging\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import gc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62db6a6-2d46-48d1-b70c-bd5add1ad64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32934d3b-7744-4ee0-b847-d2c6376acfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed = 100\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c42f6a-9e12-4f71-bec1-81dfbcffee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(name: str, file_path: str, stream=False) -> logging.RootLogger:\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s | %(name)s | %(levelname)s | %(message)s')\n",
    "    stream_handler = logging.StreamHandler()\n",
    "    file_handler = logging.FileHandler(file_path)\n",
    "\n",
    "    stream_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    if stream:\n",
    "        logger.addHandler(stream_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e006271-fc7f-4643-8663-3c41b75c6661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def get_metric_fn(y_pred, y_answer, y_prob):\n",
    "    \"\"\" 성능을 반환하는 함수\n",
    "    \"\"\"\n",
    "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
    "    accuracy = accuracy_score(y_answer, y_pred)\n",
    "    auroc = roc_auc_score(y_answer, y_prob)\n",
    "    return accuracy, auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f9cb90-f191-4d24-90b7-cd9882aa5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# working directory 지정\n",
    "ROOT_PATH = './'\n",
    "TRAIN_DIR = os.path.join(ROOT_PATH, 'train')\n",
    "RESULT_DIR = os.path.join(ROOT_PATH, 'results')\n",
    "WEIGHT_DIR = os.path.join(ROOT_PATH, 'weights')\n",
    "NUMPY_DIR = os.path.join(ROOT_PATH, 'numpy')\n",
    "CSV_DIR = os.path.join(ROOT_PATH, 'csv')\n",
    "TEST_ANNOT_DIR = os.path.join(ROOT_PATH, 'test_annot')\n",
    "\n",
    "if not os.path.isdir(RESULT_DIR):\n",
    "    os.makedirs(RESULT_DIR)\n",
    "\n",
    "# hyper-parameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 1e-4\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "INPUT_SHAPE = (180, 90)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f974610f-4c0c-4ee4-9caf-3568483e7fc4",
   "metadata": {},
   "source": [
    "## Test DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef69b32-36d9-41a8-947c-96efac351b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, db, mode, transform):\n",
    "\n",
    "        self.db = db\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = copy.deepcopy(self.db.loc[index])\n",
    "\n",
    "        # Loading image\n",
    "        cvimg = cv2.imread(data['img_path'], cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
    "        if not isinstance(cvimg, np.ndarray):\n",
    "            raise IOError(\"Fail to read %s\" % data['img_path'])\n",
    "\n",
    "        # Preprocessing images\n",
    "        trans_image = self.transform(Image.fromarray(cvimg))\n",
    "\n",
    "        return trans_image, data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b4b2291-64f0-46e0-b984-bed76ab13e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loader(data_dir=TEST_ANNOT_DIR):\n",
    "    print('Loading ' + ' dataset..')\n",
    "    if not os.path.isdir(data_dir):\n",
    "        print(f'!!! Cannot find {data_dir}... !!!')\n",
    "        sys.exit()\n",
    "        \n",
    "    mask_image_list = os.listdir(os.path.join(data_dir, 'Mask'))\n",
    "    nomask_image_list = os.listdir(os.path.join(data_dir, 'NoMask'))\n",
    "    mask_image_list = [item for item in mask_image_list if item[-4:] == '.png']\n",
    "    nomask_image_list = [item for item in nomask_image_list  if item[-4:] == '.png']\n",
    "    mask_image_path = list(map(lambda x : os.path.join(data_dir, 'Mask', x), mask_image_list))\n",
    "    nomask_image_path = list(map(lambda x : os.path.join(data_dir, 'NoMask', x), nomask_image_list))\n",
    "\n",
    "    # encoding label (Mask : 1, No Mask : 0)\n",
    "    mask_df = pd.DataFrame({'img_path':mask_image_path, 'label':np.ones(len(mask_image_list))})\n",
    "    nomask_df = pd.DataFrame({'img_path':nomask_image_path, 'label':np.zeros(len(nomask_image_list))})\n",
    "    db = mask_df.append(nomask_df, ignore_index=True)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3de052-b875-4c15-9611-d44aeeada767",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(os.path.join(TEST_ANNOT_DIR, 'test.pkl')):\n",
    "    test_db = pd.read_pickle(os.path.join(TEST_ANNOT_DIR, 'test.pkl'))\n",
    "else:\n",
    "    test_db = test_loader()\n",
    "    test_db.to_pickle(os.path.join(TEST_ANNOT_DIR, 'test.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda8ec16-924b-4345-b917-a3eca31a0a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                                transforms.Resize(INPUT_SHAPE),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3826ee63-b05c-4ff0-a6bb-50391ec0e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(db=test_db, mode='test', transform=transform)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc2076d-e62a-4e0a-b989-adee1c0f9e33",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8479d9-a0a2-41c5-bde9-d8a5c561d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFF_BACKBONES = [\n",
    "    'efficientnet_b1',\n",
    "    'efficientnet_b1_pruned',\n",
    "    'tf_efficientnet_b1_ns',\n",
    "    'tf_efficientnet_b4_ns',\n",
    "    'tf_efficientnet_b7_ns',\n",
    "    'efficientnetv2_rw_s',\n",
    "    'efficientnetv2_rw_m',\n",
    "    'tf_efficientnetv2_s_in21k',\n",
    "    'tf_efficientnetv2_s_in21ft1k',\n",
    "    'tf_efficientnetv2_m_in21k',\n",
    "    'tf_efficientnetv2_m_in21ft1k',\n",
    "    'tf_efficientnetv2_l_in21k',\n",
    "]\n",
    "NFN_BACKBONES = [\n",
    "    'eca_nfnet_l0',\n",
    "    'eca_nfnet_l1',\n",
    "    'eca_nfnet_l2',\n",
    "    'dm_nfnet_f2',\n",
    "    'dm_nfnet_f4',\n",
    "    'dm_nfnet_f6',\n",
    "]\n",
    "    \n",
    "DEIT_BACKBONES = [\n",
    "    'deit_base_distilled_patch16_224',\n",
    "    'deit_base_distilled_patch16_384'   \n",
    "]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9470b300-e1da-40f0-8d0d-02cde14c622a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for efficientnet\n",
    "class EFFMaskClassifier(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(EFFMaskClassifier, self).__init__()\n",
    "        self.model = timm.create_model(backbone, pretrained=True)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, 1)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11fd8c3c-bcb7-4615-8ab0-b25a72c9dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for nfnet\n",
    "class NFNMaskClassifier(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(NFNMaskClassifier, self).__init__()\n",
    "        self.model = timm.create_model(backbone, pretrained=True)\n",
    "        n_features = self.model.head.fc.in_features\n",
    "        self.model.head.fc = nn.Linear(n_features, 1)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b81a003-75ab-4879-9457-2bdf7dde7a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deit\n",
    "class DEITMaskClassifier(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(DEITMaskClassifier, self).__init__()\n",
    "        self.model = timm.create_model(backbone, pretrained=True)\n",
    "        in_features_head = self.model.head.in_features\n",
    "        in_features_head_dist = self.model.head_dist.in_features\n",
    "        \n",
    "        self.model.head = nn.Linear(in_features_head, 1)\n",
    "        self.model.head_dist = nn.Linear(in_features_head_dist, 1)\n",
    "\n",
    "    def forward(self, input_img):\n",
    "        x = self.model(input_img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901ee67-6478-4f2f-9286-d02fa8396594",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07535ac6-552c-40c7-845f-759be5edcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    \"\"\" Trainer\n",
    "        epoch에 대한 학습 및 검증 절차 정의\n",
    "    \"\"\"\n",
    "    def __init__(self, criterion, model, device, metric_fn, optimizer=None, scheduler=None, logger=None):\n",
    "        \"\"\" 초기화\n",
    "        \"\"\"\n",
    "        \n",
    "        self.criterion = criterion\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.logger = logger\n",
    "        self.scheduler = scheduler\n",
    "        self.metric_fn = metric_fn\n",
    "\n",
    "    def train_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 학습 절차\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        train_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            pred = self.model(img).squeeze()\n",
    "\n",
    "            loss = self.criterion(pred, label)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "            train_total_loss += loss.item()\n",
    "            prob_lst.extend(pred.cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend((pred > 0.5).float().cpu().tolist())\n",
    "        self.train_mean_loss = train_total_loss / batch_index\n",
    "        self.train_score, auroc = self.metric_fn(y_pred=pred_lst, y_answer=target_lst, y_prob=prob_lst)\n",
    "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, ROC: {auroc}'\n",
    "        print(msg)\n",
    "        \n",
    "\n",
    "    def validate_epoch(self, dataloader, epoch_index):\n",
    "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        val_total_loss = 0\n",
    "        target_lst = []\n",
    "        pred_lst = []\n",
    "        prob_lst = []\n",
    "\n",
    "        for batch_index, (img, label) in enumerate(dataloader):\n",
    "            img = img.to(self.device)\n",
    "            label = label.to(self.device)\n",
    "            pred = self.model(img).squeeze()\n",
    "            ## coordinate loss\n",
    "            loss = self.criterion(pred, label)\n",
    "            val_total_loss += loss.item()\n",
    "            prob_lst.extend(pred.cpu().tolist())\n",
    "            target_lst.extend(label.cpu().tolist())\n",
    "            pred_lst.extend((pred > 0.5).float().cpu().tolist())\n",
    "        self.val_mean_loss = val_total_loss / batch_index\n",
    "        self.validation_score, auroc = self.metric_fn(y_pred=pred_lst, y_answer=target_lst, y_prob=prob_lst)\n",
    "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, ROC: {auroc}'\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bc217c-9dfa-445f-8d9d-eeaed5ad841d",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70db6397-3c89-4f17-b932-20ce480a38e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE = EFF_BACKBONES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b1b24d6-7839-4b67-b321-12eff142c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EFFMaskClassifier(BACKBONE).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d71965-fec4-46c4-bcd2-71ddfa483655",
   "metadata": {},
   "source": [
    "## Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d479cb6-5730-481e-b3b6-8b975485248d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Val loss: 0.9460562933788341, Acc: 0.8021442495126706, ROC: 0.8697803514376996\n"
     ]
    }
   ],
   "source": [
    "TRAINED_MODEL_PATH = os.path.join(WEIGHT_DIR, f'{BACKBONE}_best.pt')\n",
    "\n",
    "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
    "\n",
    "# Prediction\n",
    "file_num_lst = []\n",
    "pred_lst = []\n",
    "prob_lst = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_index, (img, file_num) in enumerate(test_dataloader):\n",
    "        img = img.to(device)\n",
    "        pred = model(img).squeeze()\n",
    "        file_num_lst.extend(list(file_num))\n",
    "        pred_lst.extend((pred > 0.5).float().cpu().tolist())\n",
    "        prob_lst.extend(pred.cpu().tolist())\n",
    "df = pd.DataFrame({'file_name':list(map(int,file_num_lst)), 'answer':pred_lst, 'prob':prob_lst})\n",
    "df.sort_values(by=['file_name'], inplace=True)\n",
    "df.to_csv(os.path.join(RESULT_DIR, f'mask_pred_with_{BACKBONE}.csv'), index=False)\n",
    "\n",
    "system_logger = get_logger(name='train',file_path='train_log.log')\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "metric_fn = get_metric_fn\n",
    "scheduler =  optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer, T_0=6, T_mult=1, eta_min=1e-6)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "trainer = Trainer(criterion, model, device, metric_fn, optimizer, scheduler, logger=system_logger)\n",
    "\n",
    "trainer.validate_epoch(test_dataloader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e520cc0-0d61-4d81-a1b3-e0b0c3d22db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;230m\u001b[38;5;203m    ⸂⸂⸜(രᴗര๑)⸝⸃⸃    화이팅!    ⸂⸂⸜(രᴗര๑)⸝⸃⸃    \u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "print(f'\\033[48;5;230m\\033[38;5;203m    ⸂⸂⸜(രᴗര๑)⸝⸃⸃    화이팅!    ⸂⸂⸜(രᴗര๑)⸝⸃⸃    \\033[0;0m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e526fb-ca49-40b8-9132-16a1efff7363",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
